{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Sequence fetching, Li et al.\n",
    "___\n",
    "Herschlag lab <br>\n",
    "2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as pl\n",
    "from Bio import SeqIO\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "import multiprocessing as mp\n",
    "from subprocess import PIPE\n",
    "import subprocess\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Prepare the Li et al. organism list by pre-processing and chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21498 Unique Organisms\n"
     ]
    }
   ],
   "source": [
    "liOrgListPath = 'Lietal_OrgTempList/temperature_data_full.tsv'\n",
    "\n",
    "temped_Li_list = pd.read_csv(liOrgListPath, delimiter = '\\t').drop_duplicates()\n",
    "print(len(temped_Li_list), 'Unique Organisms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split taxonomic information by genus and species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>organism</th>\n",
       "      <th>domain</th>\n",
       "      <th>temperature</th>\n",
       "      <th>taxid</th>\n",
       "      <th>lineage_text</th>\n",
       "      <th>superkingdom</th>\n",
       "      <th>phylum</th>\n",
       "      <th>class</th>\n",
       "      <th>order</th>\n",
       "      <th>family</th>\n",
       "      <th>genus</th>\n",
       "      <th>genus_name</th>\n",
       "      <th>species_name</th>\n",
       "      <th>genus_species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abiotrophia_adiacens</td>\n",
       "      <td>Bacteria</td>\n",
       "      <td>37</td>\n",
       "      <td>46124</td>\n",
       "      <td>cellular organisms; Bacteria; Terrabacteria gr...</td>\n",
       "      <td>2</td>\n",
       "      <td>1239.0</td>\n",
       "      <td>91061.0</td>\n",
       "      <td>186826.0</td>\n",
       "      <td>186828.0</td>\n",
       "      <td>117563.0</td>\n",
       "      <td>Abiotrophia</td>\n",
       "      <td>adiacens</td>\n",
       "      <td>Abiotrophia adiacens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abiotrophia_balaenopterae</td>\n",
       "      <td>Bacteria</td>\n",
       "      <td>37</td>\n",
       "      <td>137733</td>\n",
       "      <td>cellular organisms; Bacteria; Terrabacteria gr...</td>\n",
       "      <td>2</td>\n",
       "      <td>1239.0</td>\n",
       "      <td>91061.0</td>\n",
       "      <td>186826.0</td>\n",
       "      <td>186828.0</td>\n",
       "      <td>117563.0</td>\n",
       "      <td>Abiotrophia</td>\n",
       "      <td>balaenopterae</td>\n",
       "      <td>Abiotrophia balaenopterae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abiotrophia_defectiva</td>\n",
       "      <td>Bacteria</td>\n",
       "      <td>37</td>\n",
       "      <td>46125</td>\n",
       "      <td>cellular organisms; Bacteria; Terrabacteria gr...</td>\n",
       "      <td>2</td>\n",
       "      <td>1239.0</td>\n",
       "      <td>91061.0</td>\n",
       "      <td>186826.0</td>\n",
       "      <td>186827.0</td>\n",
       "      <td>46123.0</td>\n",
       "      <td>Abiotrophia</td>\n",
       "      <td>defectiva</td>\n",
       "      <td>Abiotrophia defectiva</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    organism    domain  temperature   taxid  \\\n",
       "0       abiotrophia_adiacens  Bacteria           37   46124   \n",
       "1  abiotrophia_balaenopterae  Bacteria           37  137733   \n",
       "2      abiotrophia_defectiva  Bacteria           37   46125   \n",
       "\n",
       "                                        lineage_text  superkingdom  phylum  \\\n",
       "0  cellular organisms; Bacteria; Terrabacteria gr...             2  1239.0   \n",
       "1  cellular organisms; Bacteria; Terrabacteria gr...             2  1239.0   \n",
       "2  cellular organisms; Bacteria; Terrabacteria gr...             2  1239.0   \n",
       "\n",
       "     class     order    family     genus   genus_name   species_name  \\\n",
       "0  91061.0  186826.0  186828.0  117563.0  Abiotrophia       adiacens   \n",
       "1  91061.0  186826.0  186828.0  117563.0  Abiotrophia  balaenopterae   \n",
       "2  91061.0  186826.0  186827.0   46123.0  Abiotrophia      defectiva   \n",
       "\n",
       "               genus_species  \n",
       "0       Abiotrophia adiacens  \n",
       "1  Abiotrophia balaenopterae  \n",
       "2      Abiotrophia defectiva  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temped_Li_list['genus_name'] = temped_Li_list.organism.apply(lambda s: s.split('_')[0]).str.capitalize()\n",
    "temped_Li_list['species_name'] = temped_Li_list.organism.apply(lambda s: s.split('_')[1])\n",
    "temped_Li_list['genus_species'] = temped_Li_list.genus_name + ' ' + temped_Li_list.species_name\n",
    "\n",
    "temped_Li_list.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove any organisms without a defined species name (species_name == 'sp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genus_species</th>\n",
       "      <th>temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abiotrophia adiacens</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abiotrophia balaenopterae</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abiotrophia defectiva</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               genus_species  temperature\n",
       "0       Abiotrophia adiacens           37\n",
       "1  Abiotrophia balaenopterae           37\n",
       "2      Abiotrophia defectiva           37"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20897 Clean Organisms\n"
     ]
    }
   ],
   "source": [
    "temped_Li_list_clean = temped_Li_list[['genus_species', 'temperature']].loc[temped_Li_list.species_name != 'sp']\n",
    "\n",
    "display(temped_Li_list_clean.head(3))\n",
    "print(len(temped_Li_list_clean), 'Clean Organisms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fetching sequences will require chunking the organism list (to keep Entrez query lengths small enough)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNKED_ROOT = Path('Lietal_OrgTempList/Chunked_Temp_List')\n",
    "NUM_CHUNKS = 4\n",
    "\n",
    "for index, df in enumerate(list(np.array_split(temped_Li_list_clean, NUM_CHUNKS))):\n",
    "    chunkPath = CHUNKED_ROOT.joinpath('LiTempedOrgs_Chunk_{}.txt'.format(index+1))\n",
    "    with open(chunkPath, 'w') as outPath:\n",
    "        outPath.write('\\n'.join(df.genus_species.values.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the records for use in Entrezpy Fetching\n",
    "!cat ./Lietal_OrgTempList/Chunked_Temp_List/*_Chunk_*.txt > ./Lietal_OrgTempList/Chunked_Temp_List/LiTempedOrgs_All.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Also export the full cleaned list for downstream use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "temped_Li_list_clean.to_csv('Lietal_OrgTempList/LietAl_temperature_data_culled.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "\n",
    "## 3. Fetch the UIDs for each query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enzymeListToDict(handle):\n",
    "    \"\"\"\n",
    "    \n",
    "    Arguments:\n",
    "    \n",
    "    Returns:\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    organisms = {}\n",
    "    indices = []\n",
    "    names = []\n",
    "    index = 0\n",
    "    with open(handle) as el:\n",
    "        for line in el.readlines():\n",
    "            if index%2 == 0:\n",
    "                indices.append(line.strip()[1:])\n",
    "            else:\n",
    "                names.append(line.strip())\n",
    "            index += 1\n",
    "    names = dict(zip(indices, names))\n",
    "    return names\n",
    "\n",
    "def fetchOrganisms(filepath):\n",
    "    \"\"\"\n",
    "    \n",
    "    Arguments:\n",
    "    \n",
    "    Returns:\n",
    "    \n",
    "    \"\"\"\n",
    "    with open(filepath) as f:\n",
    "        o = f.readlines()\n",
    "    organisms = [x.strip() for x in o if not x.strip() == 'Escherichia coli' and not x.strip() == 'Pseudomonas aeruginosa']\n",
    "    return organisms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getUIDs(enzyme, outrecpath, chunkSize):\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    Arguments:\n",
    "    \n",
    "    Returns:\n",
    "    \n",
    "    \"\"\"\n",
    "    python = '/Users/varundeepakgudhe/opt/anaconda3/bin/python'\n",
    "    program = 'Scripts/entrezpy_UIDfetch.py'\n",
    "    email = 'vgudhe@ncsu.edu'\n",
    "    orglistpath = 'Lietal_OrgTempList/Chunked_Temp_List/LiTempedOrgs_All.txt'\n",
    "    \n",
    "    def writeUIDsToDB(enzymeName, uidList, db_path):\n",
    "        with open(db_path, \"a+\") as db:\n",
    "            db.write('{}\\t{}\\t{}\\n'.format(enzymeName, len(uidList), str(uidList)))\n",
    "\n",
    "    uidList = []\n",
    "    for i in range(4):\n",
    "        args = [python, program, email, enzyme, i*chunkSize, (i+1)*chunkSize, orglistpath]\n",
    "        statement = '{} {} -e {} -E \"{}\" -S {} -n {} -p \"{}\"'.format(*args)\n",
    "\n",
    "        entrezQuery = subprocess.Popen(statement, stdout=PIPE, shell=True)\n",
    "        results = entrezQuery.communicate()[0]\n",
    "        n = ast.literal_eval(results.decode('utf-8').strip())\n",
    "        uidList.extend(n)\n",
    "\n",
    "    writeUIDsToDB(enzyme, uidList, db_path = outrecpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 enzymes in raw Brenda list\n",
      "1 unique enzymes after cleaning\n"
     ]
    }
   ],
   "source": [
    "raw_enzyme_list = Path('BrendaEnzymeList/enzymeList_Brenda_Raw_biotin_carboxylase.txt')\n",
    "raw_enzyme_series = pd.Series(enzymeListToDict(raw_enzyme_list))\n",
    "\n",
    "# Remove missing entry, de-replicate\n",
    "raw_enzyme_series_dereplicated = raw_enzyme_series.loc[~(raw_enzyme_series.values=='')].drop_duplicates()\n",
    "\n",
    "print('{} enzymes in raw Brenda list\\n{} unique enzymes after cleaning'.format(len(raw_enzyme_series), len(raw_enzyme_series_dereplicated)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Collect UIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See 4a–b.\n",
    "orglistpath = 'Lietal_OrgTempList/Chunked_Temp_List/LiTempedOrgs_All.txt'\n",
    "\n",
    "enzymes = list(raw_enzyme_series_dereplicated.values)\n",
    "orglist = fetchOrganisms(orglistpath)\n",
    "chunkSize = int(len(orglist)/4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Total time: ~7h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "outrecpath = 'Lietal_FetchedSeqs/1912_Lietal_UIDLists.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "getUIDs(\"biotin carboxylase\",outrecpath, chunkSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "\n",
    "## 4. Parse GIs (UIDs for NR DB) and map to their accessions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Parse and dereplicate the UIDs (~5min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total UID count pre-mapping: 50265\n",
      "Unique UID count pre-mapping: 37685\n"
     ]
    }
   ],
   "source": [
    "uids = []\n",
    "outrecpath = 'Lietal_FetchedSeqs/1912_Lietal_UIDLists.txt'\n",
    "\n",
    "with open(outrecpath, 'r') as reader:\n",
    "    l = reader.readline()\n",
    "    while l:\n",
    "        recuids = ast.literal_eval(l.split('\\t')[-1])\n",
    "        uids.extend(recuids)\n",
    "        l = reader.readline()\n",
    "        \n",
    "# Dereplicate UIDs\n",
    "uidSet = set(uids)\n",
    "\n",
    "print('Total UID count pre-mapping: {}\\nUnique UID count pre-mapping: {}'.format(len(uids),len(uidSet)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Write the dereplicated UIDs to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanUIDPath = 'Lietal_FetchedSeqs/CleanUIDsForMapping.txt'\n",
    "\n",
    "with open(cleanUIDPath, 'a+') as uid_path:\n",
    "    uid_path.write(''.join(['{}\\n'.format(uid) for uid in uidSet]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(uids)\n",
    "del(uidSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. Perform the mapping from UID (GI for NR proteins) to Acc using the NCBI tool [gi2accession](https://ncbiinsights.ncbi.nlm.nih.gov/2016/12/23/converting-lots-of-gi-numbers-to-accession-version/) (~10min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cat Lietal_FetchedSeqs/CleanUIDsForMapping.txt | /Users/varundeepakgudhe/opt/anaconda3/envs/py27/bin/python Scripts/gi2accession.py -d /Volumes/MyPassport/Dr.Raffael/gi2acc_lmdb.db > Lietal_FetchedSeqs/MappedCleanUIDs.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d. Clean the mapped GIs->Accession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_UIDs = \"Lietal_FetchedSeqs/MappedCleanUIDs.txt\"\n",
    "mappedAccessions = pd.read_csv(clean_UIDs, \n",
    "                               delimiter = '\\t', \n",
    "                               names = ['GI', 'Acc', 'Length']\n",
    "                               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Identify the non-mapped GIs to be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappedAccessions['GI'] = mappedAccessions['GI'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GI</th>\n",
       "      <th>Acc</th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [GI, Acc, Length]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missingAccessions = mappedAccessions.loc[(mappedAccessions.GI.str.contains('not found',na=False))]\n",
    "missingAccessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 of 37685 total accessions weren't successfully mapped (0.0%)\n",
      "Proceeding with 37685 mapped and culled accessions\n"
     ]
    }
   ],
   "source": [
    "mappedAccessionsCulled = mappedAccessions.drop(labels = missingAccessions.index.values)\n",
    "mappedAccessionsCulled['GI'] = mappedAccessionsCulled.GI.astype(np.int32)\n",
    "mappedAccessionsCulled['Acc'] = mappedAccessionsCulled.Acc.astype(str)\n",
    "mappedAccessionsCulled['Length'] = mappedAccessionsCulled.Length.astype(np.int32)\n",
    "\n",
    "print(\"{} of {} total accessions weren't successfully mapped ({}%)\".format(len(missingAccessions), \n",
    "                                                                           len(mappedAccessions), \n",
    "                                                                           round(100*(len(missingAccessions)/len(mappedAccessions)), \n",
    "                                                                                 5)))\n",
    "print(\"Proceeding with {} mapped and culled accessions\".format(len(mappedAccessionsCulled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GI</th>\n",
       "      <th>Acc</th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1662646231</td>\n",
       "      <td>CAK3272800.1</td>\n",
       "      <td>447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>619865662</td>\n",
       "      <td>GAJ52212.1</td>\n",
       "      <td>1095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1456951037</td>\n",
       "      <td>SWJ88283.1</td>\n",
       "      <td>449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           GI           Acc  Length\n",
       "0 -1662646231  CAK3272800.1     447\n",
       "1   619865662    GAJ52212.1    1095\n",
       "2  1456951037    SWJ88283.1     449"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine a sample of the results!\n",
    "mappedAccessionsCulled.iloc[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hold the dictionary of Acc->GIs (a 1:1 mapping) in memory for part **5.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "accessionDict = mappedAccessionsCulled.set_index('Acc')['GI'].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 5. Parse the Non-Redundant Database (nr.gz) and extract a fasta of just our target sequences (1 pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import copy\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm\n",
    "from Bio import SeqIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Prepare the maps needed to identify desired seqs in nr.gz and to gather the needed data in their new fasta headers\n",
    " - nr.gz has the protein Accession and the organism name in the headers. To do this we need to hold 2 dictionaries in memory while parsing:\n",
    "     - Map from accession -> GI\n",
    "     - Map from GI -> [all enzyme query terms returning that GI]\n",
    "         - VERY IMPORTANT: A single GI can correspond to MORE THAN ONE ENZYME! (This alters how we parcel out the seqs and how we make the GI->Enzyme mapping below)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i. First read the list of GIs (as a string of strings) into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic parser for the dumped UID lists to generate a flat dictionary to look up UID->Enzyme efficiently\n",
    "UIDListoutrecpath = 'Lietal_FetchedSeqs/1912_Lietal_UIDLists.txt'\n",
    "\n",
    "recs = {}\n",
    "with open(UIDListoutrecpath, 'r') as outUIDs:\n",
    "    l = outUIDs.readline()\n",
    "    while l:\n",
    "        data = l.strip().split('\\t')[0:3]\n",
    "        recs[data[0]] = data[2]\n",
    "        l = outUIDs.readline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii. Then convert to a real list of strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  7.00it/s]\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "cleanrecs = {} # Enzyme -> unique set of GIs\n",
    "for k, v in tqdm(recs.items()):\n",
    "    cleanrecs[k] = set(ast.literal_eval(v)) # Just convert the recs to actual list. Dereplicate them BY ENZYME at the same time!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### iii. Finally build the dictionary from GI->[EnzymeName1, EnzymeName2, ...]\n",
    " - VERY IMPORTANT: A single GI can correspond to MORE THAN ONE ENZYME! (This alters how we parcel out the seqs and how we make the GI->Enzyme mapping in this cell)\n",
    " - We also index prepend a padded 10-digit index in front of the enzyme name (`str(index).zfill(10)+enzymeName`), which will be parsed out later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 25.58it/s]\n"
     ]
    }
   ],
   "source": [
    "# VERY IMPORTANT: A single GI can correspond to MORE THAN ONE ENZYME! (This alters how we parcel out the seqs and how we make the GI->Enzyme mapping in this cell)\n",
    "# Goal:bBuild a flat dictionary from GI:[EnzymeName1+'+{}'.format(index), EnzymeName2+'+{}'.format(index), ...]\n",
    "\n",
    "flatDB = {}\n",
    "already_present_count = 0\n",
    "for enzymeName, GISet in tqdm(cleanrecs.items()):\n",
    "    for index, GI in enumerate(GISet): # For a given enzyme & associated list of GIs\n",
    "        # Catch cases where one GI corresponds to more than one enzyme!\n",
    "        if GI in flatDB.keys():\n",
    "            flatDB[GI].append(str(index).zfill(10)+enzymeName)\n",
    "            already_present_count+=1\n",
    "        else:\n",
    "            flatDB[GI] = [str(index).zfill(10)+enzymeName]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iv. Dump the resulting dictionary to a JSON file in case we have to restart the kernel (as generating it was time intensive)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('Lietal_FetchedSeqs/GI_to_Enzyme_Map.json', 'a+') as fp:\n",
    "    json.dump(flatDB, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### And just for curiosity's sake..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# GIs dereplicated on enzyme AND across enzymes: 37685\n",
      "# GIs appearing in more than 1 enzyme: 0\n"
     ]
    }
   ],
   "source": [
    "moreThan1inflatDB = {k:v for k, v in flatDB.items() if len(v) > 1}\n",
    "\n",
    "print('# GIs dereplicated on enzyme AND across enzymes: {}'.format(len(flatDB)))\n",
    "print('# GIs appearing in more than 1 enzyme: {}'.format(len(moreThan1inflatDB)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Free the intermediate dictionaries to free up memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(recs)\n",
    "del(cleanrecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Parse nr.gz entry by entry, identify seqs corresponding to GIs we want to keep, and write each desired seq to a fasta file with the corresponding query term(s) with a custom header (~3h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matching Seqs: 100%|█████████| 595907626/595907626 [2:07:31<00:00, 77879.14it/s]\n"
     ]
    }
   ],
   "source": [
    "nrgs = '/Volumes/MyPassport/Dr.Raffael/nr.gz'\n",
    "parsedEnzymeRoot = Path('Lietal_FetchedSeqs/parsed_fastas')\n",
    "\n",
    "#### Dictionaries\n",
    "# accessionDict\n",
    "# flatDB->Enzyme(s)\n",
    "\n",
    "with gzip.open(nrgs, 'rt') as handle:\n",
    "    for record in tqdm(SeqIO.parse(handle, 'fasta'), total = 595907626, desc = 'Matching Seqs'):\n",
    "        # '\\x01' invisible delimiter\n",
    "        splitHeaders = record.description.split('\\x01')\n",
    "        acc_org = []\n",
    "        for entry in splitHeaders:\n",
    "            acc = entry.split(' ')[0]\n",
    "            m = re.search('\\[.*?\\]$', entry)\n",
    "            if m:\n",
    "                organism = m.group()[1:-1]\n",
    "            else:\n",
    "                organism = 'Missing'\n",
    "            acc_org.append([acc, organism])\n",
    "            \n",
    "        for a, org in acc_org:\n",
    "            if a in accessionDict.keys():\n",
    "            \n",
    "                gi = str(abs(accessionDict[a]))\n",
    "             \n",
    "                try:\n",
    "                    for enzyme in [e[10:] for e in flatDB[gi]]:\n",
    "                        r = copy.copy(record)\n",
    "                        r.id = '{}|{}|{}|{}'.format(a, gi, enzyme, org)\n",
    "                        r.name = ''\n",
    "                        r.description = ''\n",
    "                        outFastaPath = parsedEnzymeRoot.joinpath(Path('{}.fa'.format(enzyme.replace(' ', '_').replace('/', '__'))))\n",
    "                        with open(outFastaPath, 'a+') as h:\n",
    "                            SeqIO.write([r], h, 'fasta')\n",
    "                except:\n",
    "                    pass\n",
    "            else:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Characterize the written files to check how the parsing went\n",
    "    - How many files were written?\n",
    "    - How many sequences do each file have in them?\n",
    "    - What's the distribution of the lengths of sequences in each file?\n",
    "    - What fraction of sequences in each file have a missing organism or organism without a species identifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 14.12it/s]\n"
     ]
    }
   ],
   "source": [
    "names_sizes = []\n",
    "for path in tqdm(parsedEnzymeRoot.iterdir()):\n",
    "    if path.is_file():\n",
    "        recs = [record for record in SeqIO.parse(path, 'fasta')]\n",
    "        lens = [len(s) for s in recs]\n",
    "        unique_organisms = set([r.description.split('|')[-1] for r in recs if 'Missing' not in r.description])\n",
    "\n",
    "        names_sizes.append({'Name': Path(path).stem, \n",
    "                            'File_Size': Path(path).stat().st_size,\n",
    "                            'Num_Seqs': len(recs),\n",
    "                            'Mean_Len': np.mean(lens),\n",
    "                            'Std_Len': np.std(lens),\n",
    "                            'Num_Unique_Organisms': len(unique_organisms)\n",
    "                           })\n",
    "\n",
    "names_sizes_df = pd.DataFrame(names_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>File_Size</th>\n",
       "      <th>Num_Seqs</th>\n",
       "      <th>Mean_Len</th>\n",
       "      <th>Std_Len</th>\n",
       "      <th>Num_Unique_Organisms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>biotin_carboxylase</td>\n",
       "      <td>4294006</td>\n",
       "      <td>8137</td>\n",
       "      <td>451.398304</td>\n",
       "      <td>171.93907</td>\n",
       "      <td>3132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Name  File_Size  Num_Seqs    Mean_Len    Std_Len  \\\n",
       "0  biotin_carboxylase    4294006      8137  451.398304  171.93907   \n",
       "\n",
       "   Num_Unique_Organisms  \n",
       "0                  3132  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_sizes_df.sort_values('Num_Unique_Organisms', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Generate a cleaned copy of the fastas with seqs of organisms in our final bacterial tree only, and seqs consisting of only canonical residues, in the proper *Genus species* form (remove sub-species information)\n",
    "    - Remove sequences corresponding to organisms that do not appear in the culled tree\n",
    "    - Remove sequences containing non-standard residues\n",
    "    - Clean the fasta headers such that the organism header is solely 'Genus species'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Import the list of organisms from the final bacterial tree. This is our \"reference\" set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tree has 5852 organisms\n"
     ]
    }
   ],
   "source": [
    "from Bio import Phylo\n",
    "\n",
    "treeRoot = Path('/Users/varundeepakgudhe/Downloads/Dr.Rafael_prev_res_notebooks/Tree_Generation/Processed_Trees/Final_BacterialTrees')\n",
    "tree = Phylo.read(treeRoot.joinpath('bac120_r86.2_dedup_droppedTipsRenamed_genusSpecies_nonCollapsed.phyloxml'), 'phyloxml')\n",
    "treeOrganisms = {t.name for t in tree.get_terminals()}\n",
    "\n",
    "print('The tree has {} organisms'.format(len(treeOrganisms)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Our allowed amino acids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protein Alphabet: {'W', 'L', 'I', 'D', 'V', 'G', 'T', 'F', 'P', 'C', 'K', 'Y', 'R', 'E', 'M', 'N', 'A', 'Q', 'H', 'S'}\n"
     ]
    }
   ],
   "source": [
    "#from Bio.Alphabet.IUPAC import IUPACProtein\n",
    "\n",
    "PROT_LETTERS = {'E', 'C', 'N', 'R', 'A', 'M', 'P', 'H', 'D', 'V', 'I', 'Y', 'K', 'F', 'W', 'T', 'G', 'Q', 'L', 'S'}\n",
    "print('Protein Alphabet: {}'.format(PROT_LETTERS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Execute the cleaning (~45 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/var/folders/lk/f1snn09n3svd7pdwh0yw2pp40000gn/T/ipykernel_2446/1936245981.py:52: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  esccount = pd.Series([' '.join(r[0:2]) in treeOrganisms for r in escapees]).value_counts().loc[True]\n",
      "1it [00:00,  4.61it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Enzyme</th>\n",
       "      <th>Culled</th>\n",
       "      <th>Retained</th>\n",
       "      <th>EscapingConditions</th>\n",
       "      <th>Escapees_In_Tree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>biotin_carboxylase</td>\n",
       "      <td>44</td>\n",
       "      <td>8093</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Enzyme  Culled  Retained  EscapingConditions  Escapees_In_Tree\n",
       "0  biotin_carboxylase      44      8093                   0                 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "oldRoot = Path('Lietal_FetchedSeqs/parsed_fastas/')\n",
    "\n",
    "newRoot = Path('Lietal_FetchedSeqs/parsed_fastas_cleaned')\n",
    "\n",
    "\n",
    "cleaning_summary = []\n",
    "for oldFile in tqdm(oldRoot.iterdir()):\n",
    "    if oldFile.is_file() and \".ipynb_checkpoints\" not in oldFile.parts:\n",
    "        newFile = newRoot.joinpath(oldFile.name)\n",
    "        culledCount = 0\n",
    "        retainedCount = 0\n",
    "        escapingCondition = 0\n",
    "        escapees = []\n",
    "        with open(newFile, 'a+') as nf:\n",
    "            for record in SeqIO.parse(oldFile, 'fasta'):\n",
    "                organism = record.description.split('|')[-1]\n",
    "                orglist = organism.split(' ')\n",
    "             \n",
    "                # Want to short circuit with non-costly crit first to save time\n",
    "                if organism == 'Missing': #No organism\n",
    "                    culledCount+=1\n",
    "                    pass\n",
    "                elif len(orglist) == 1: #Catched genus but no species\n",
    "                    culledCount+=1\n",
    "                    pass\n",
    "                elif not all([l in PROT_LETTERS for l in set(str(record.seq))]):\n",
    "                    culledCount+=1\n",
    "                    pass # Check that only IUPAC residues in the sequence\n",
    "                else:     \n",
    "                    r = copy.copy(record)\n",
    "                    r.id = '|'.join([*record.description.split('|')[0:3], ' '.join(orglist[0:2])])\n",
    "                    r.name = ''\n",
    "                    r.description = ''\n",
    "                    SeqIO.write(r, nf, 'fasta')\n",
    "                    retainedCount+=1\n",
    "                 \n",
    "        try: \n",
    "            esccount = pd.Series([' '.join(r[0:2]) in treeOrganisms for r in escapees]).value_counts().loc[True] \n",
    "        except:\n",
    "            esccount = 0 \n",
    "\n",
    "        cleaning_summary.append({'Enzyme': oldFile.stem, 'Culled': culledCount, 'Retained': retainedCount, 'EscapingConditions': escapingCondition, 'Escapees_In_Tree': esccount})\n",
    "        # Note that 'Escapees_In_Tree' should all be 0. If they're not, we need to figure out why and catch that condition\n",
    "        # Also note that 'Enzyme' is the file handle, so EnzymeName.replace(' ', '_').replace('/', '__')\n",
    "\n",
    "cleaning_summary_df = pd.DataFrame(cleaning_summary)\n",
    "display(cleaning_summary_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Sanity checks—absolutely essential\n",
    "1. Do all of the uncaught condition records in **c.** correspond to sequences with organisms not in the tree?\n",
    "2. Do the number of fastas match the number of non-zero counts of expected UIDs (approximately)?\n",
    "    - nr.gz parsing will generate a *new* fasta only if at least one instance of that enzyme's GIs exists in it\n",
    "    - Thus, we expect the number of total enzymes with ≥1 UID to *exceed* the number of enzyme fastas written from parsing nr.gz since some \"singletons\" won't be either mapped to accessions or found in the frozen nr.gz database. This should be only a small fraction of all the enzymes though, and should only apply to enzymes with low returned UID counts\n",
    "3. Do the number of Culled + Retained closely match (they won't perfectly due to imperfect mapping) the UID count fetched originally? It's important to consider the DEREPLICATED UID count, since UIDs would be fetched only once (They are dereplicated in **4.**).  This is a good general check..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Good news: the escaping seqs weren't in the tree, as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "Name: Escapees_In_Tree, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.\n",
    "cleaning_summary_df.Escapees_In_Tree.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Parse the UID list again to generate a record (~10min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid_recs = []\n",
    "outrecpath = 'Lietal_FetchedSeqs/1912_Lietal_UIDLists.txt'\n",
    "\n",
    "with open(outrecpath, 'r') as reader:\n",
    "    l = reader.readline()\n",
    "    while l:\n",
    "        splitrec = l.split('\\t')\n",
    "        recuids = ast.literal_eval(splitrec[-1])\n",
    "        derep_recuids = set(recuids)\n",
    "        name = splitrec[0]\n",
    "        count = splitrec[1]\n",
    "        uid_recs.append({'Enzyme': name, 'Expected_Count': int(count),'Raw_UID_Count': len(recuids), 'Derep_UID_Count': len(derep_recuids)})\n",
    "        l = reader.readline()\n",
    "\n",
    "uid_rec_df = pd.DataFrame(uid_recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Expected_Count</th>\n",
       "      <th>Raw_UID_Count</th>\n",
       "      <th>Derep_UID_Count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Enzyme</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>biotin_carboxylase</th>\n",
       "      <td>50265</td>\n",
       "      <td>50265</td>\n",
       "      <td>37685</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Expected_Count  Raw_UID_Count  Derep_UID_Count\n",
       "Enzyme                                                            \n",
       "biotin_carboxylase           50265          50265            37685"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing UIDs -> Enzymes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uid_rec_df['Enzyme'] = uid_rec_df.Enzyme.str.replace(' ', '_').str.replace('/', '__')\n",
    "uid_rec_df.sort_values('Expected_Count', ascending = False, inplace = True)\n",
    "uid_rec_df.set_index('Enzyme', inplace = True)\n",
    "display(uid_rec_df.head())\n",
    "\n",
    "# Another little sanity check. We really did fetch every single UID expected from every query.\n",
    "print('Number of missing UIDs -> Enzymes')\n",
    "(uid_rec_df.Expected_Count - uid_rec_df.Raw_UID_Count).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE: Again, we expect Derep_UID_Count to EXCEED the number of UIDs actually present in our GI->Enzyme mapper because there are redundancies in GI *across enzymes* not accounted for here. About 5,000,000 (<10%) in fact.\n",
    "    - The plots show that we collected almost every sequence for every single enzyme. \n",
    "    - We were only truly missing 76471 sequences, or ~0.1% of all sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Expected_Count</th>\n",
       "      <th>Raw_UID_Count</th>\n",
       "      <th>Derep_UID_Count</th>\n",
       "      <th>Culled</th>\n",
       "      <th>Retained</th>\n",
       "      <th>EscapingConditions</th>\n",
       "      <th>Escapees_In_Tree</th>\n",
       "      <th>Total_Seqs_Gathered</th>\n",
       "      <th>Percent_Expected_Gathered</th>\n",
       "      <th>Retained_Percent_ofGathered</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Enzyme</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>biotin_carboxylase</th>\n",
       "      <td>50265</td>\n",
       "      <td>50265</td>\n",
       "      <td>37685</td>\n",
       "      <td>44</td>\n",
       "      <td>8093</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8137</td>\n",
       "      <td>21.592145</td>\n",
       "      <td>99.45926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Expected_Count  Raw_UID_Count  Derep_UID_Count  Culled  \\\n",
       "Enzyme                                                                       \n",
       "biotin_carboxylase           50265          50265            37685      44   \n",
       "\n",
       "                    Retained  EscapingConditions  Escapees_In_Tree  \\\n",
       "Enzyme                                                               \n",
       "biotin_carboxylase      8093                   0                 0   \n",
       "\n",
       "                    Total_Seqs_Gathered  Percent_Expected_Gathered  \\\n",
       "Enzyme                                                               \n",
       "biotin_carboxylase                 8137                  21.592145   \n",
       "\n",
       "                    Retained_Percent_ofGathered  \n",
       "Enzyme                                           \n",
       "biotin_carboxylase                     99.45926  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "joinedFetchedAndExpected = uid_rec_df.join(cleaning_summary_df.set_index('Enzyme'))\n",
    "joinedFetchedAndExpected['Total_Seqs_Gathered'] = joinedFetchedAndExpected.Culled + joinedFetchedAndExpected.Retained\n",
    "joinedFetchedAndExpected['Percent_Expected_Gathered'] = 100*(joinedFetchedAndExpected.Total_Seqs_Gathered)/(joinedFetchedAndExpected.Derep_UID_Count)\n",
    "joinedFetchedAndExpected['Retained_Percent_ofGathered'] = 100*(joinedFetchedAndExpected.Retained)/(joinedFetchedAndExpected.Total_Seqs_Gathered)\n",
    "\n",
    "display(joinedFetchedAndExpected.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is how many sequences are truly \"unaccounted for\" (Presumably they weren't present in nr.gz, since only a couple hundred seqs were not successfully mapped from GI -> Acc).\n",
    "    - Alternative possibility was that there were malformed fastas or errors in the databases that resulted in \"false negatives\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29548 Missing\n"
     ]
    }
   ],
   "source": [
    "print(int((joinedFetchedAndExpected.Derep_UID_Count*((100-joinedFetchedAndExpected.Percent_Expected_Gathered)/100)).sum()), \"Missing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write these statistics to a file as a record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "joinedFetchedAndExpected.to_csv('Lietal_FetchedSeqs/parsed_fastas_cleaned_stats.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which enzymes had a low percent of expected seqs obtained?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Expected_Count</th>\n",
       "      <th>Raw_UID_Count</th>\n",
       "      <th>Derep_UID_Count</th>\n",
       "      <th>Culled</th>\n",
       "      <th>Retained</th>\n",
       "      <th>EscapingConditions</th>\n",
       "      <th>Escapees_In_Tree</th>\n",
       "      <th>Total_Seqs_Gathered</th>\n",
       "      <th>Percent_Expected_Gathered</th>\n",
       "      <th>Retained_Percent_ofGathered</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Enzyme</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>biotin_carboxylase</th>\n",
       "      <td>50265</td>\n",
       "      <td>50265</td>\n",
       "      <td>37685</td>\n",
       "      <td>44</td>\n",
       "      <td>8093</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8137</td>\n",
       "      <td>21.592145</td>\n",
       "      <td>99.45926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Expected_Count  Raw_UID_Count  Derep_UID_Count  Culled  \\\n",
       "Enzyme                                                                       \n",
       "biotin_carboxylase           50265          50265            37685      44   \n",
       "\n",
       "                    Retained  EscapingConditions  Escapees_In_Tree  \\\n",
       "Enzyme                                                               \n",
       "biotin_carboxylase      8093                   0                 0   \n",
       "\n",
       "                    Total_Seqs_Gathered  Percent_Expected_Gathered  \\\n",
       "Enzyme                                                               \n",
       "biotin_carboxylase                 8137                  21.592145   \n",
       "\n",
       "                    Retained_Percent_ofGathered  \n",
       "Enzyme                                           \n",
       "biotin_carboxylase                     99.45926  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joinedFetchedAndExpected.loc[joinedFetchedAndExpected.Percent_Expected_Gathered < 90].sort_values('Percent_Expected_Gathered').head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Expected_Count</th>\n",
       "      <th>Raw_UID_Count</th>\n",
       "      <th>Derep_UID_Count</th>\n",
       "      <th>Culled</th>\n",
       "      <th>Retained</th>\n",
       "      <th>EscapingConditions</th>\n",
       "      <th>Escapees_In_Tree</th>\n",
       "      <th>Total_Seqs_Gathered</th>\n",
       "      <th>Percent_Expected_Gathered</th>\n",
       "      <th>Retained_Percent_ofGathered</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Enzyme</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>biotin_carboxylase</th>\n",
       "      <td>50265</td>\n",
       "      <td>50265</td>\n",
       "      <td>37685</td>\n",
       "      <td>44</td>\n",
       "      <td>8093</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8137</td>\n",
       "      <td>21.592145</td>\n",
       "      <td>99.45926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Expected_Count  Raw_UID_Count  Derep_UID_Count  Culled  \\\n",
       "Enzyme                                                                       \n",
       "biotin_carboxylase           50265          50265            37685      44   \n",
       "\n",
       "                    Retained  EscapingConditions  Escapees_In_Tree  \\\n",
       "Enzyme                                                               \n",
       "biotin_carboxylase      8093                   0                 0   \n",
       "\n",
       "                    Total_Seqs_Gathered  Percent_Expected_Gathered  \\\n",
       "Enzyme                                                               \n",
       "biotin_carboxylase                 8137                  21.592145   \n",
       "\n",
       "                    Retained_Percent_ofGathered  \n",
       "Enzyme                                           \n",
       "biotin_carboxylase                     99.45926  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joinedFetchedAndExpected.sort_values('Total_Seqs_Gathered', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Finally, generate a set of with the organismal growth temperatures added\n",
    "- These fastas have many replicates of the SAME sequence belonging to the same organism and different organisms (up to 75% or more for some!)\n",
    "    - BUT we can't and shouldn't dereplicates these sequences now as we need to construct a consensus sequence on a per-organism level AFTER we've done the alignment\n",
    "- And although we restricted our queries to NOT include P. aeruginosa and E. coli, many such sequences got returned\n",
    "    - But we're not going to worry about filtering them out here, because for the biggest returned sets of seqs, they're not dominating the counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Grab the Li temped list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "liOrgListPath = 'Lietal_OrgTempList/temperature_data_full.tsv'\n",
    "\n",
    "temped_Li_list = pd.read_csv(liOrgListPath, delimiter = '\\t').drop_duplicates()\n",
    "temped_Li_list['genus_name'] = temped_Li_list.organism.apply(lambda s: s.split('_')[0]).str.capitalize()\n",
    "temped_Li_list['species_name'] = temped_Li_list.organism.apply(lambda s: s.split('_')[1])\n",
    "temped_Li_list['genus_species'] = temped_Li_list.genus_name + ' ' + temped_Li_list.species_name\n",
    "\n",
    "organism_temp_dict = temped_Li_list[['genus_species', 'temperature']].set_index('genus_species').squeeze().to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Append the organismal growth temperatures from Li et al. to the fasta headers and re-write seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  5.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lietal_FetchedSeqs/parsed_fastas_cleaned/biotin_carboxylase.fa\n",
      "Count of organisms fastas which are in our org list: 7225 \n",
      "Count of organisms fastas which are not in our org list: 868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "oldRoot = Path('Lietal_FetchedSeqs/parsed_fastas_cleaned')\n",
    "\n",
    "newOut = Path('Lietal_FetchedSeqs/parsed_fastas_cleaned_temped')\n",
    "\n",
    "for parsingFile in tqdm(oldRoot.iterdir()):\n",
    "    if parsingFile.is_file() and \".ipynb_checkpoints\" not in parsingFile.parts:\n",
    "        newFile = newOut.joinpath(parsingFile.name)\n",
    "        with open(newFile, 'a+') as nf:\n",
    "            recs = []\n",
    "            inlist_count=0\n",
    "            extra_count=0\n",
    "            for record in SeqIO.parse(parsingFile, 'fasta'):\n",
    "                try:\n",
    "                    r = copy.copy(record)\n",
    "                    organism = r.description.split('|')[-1]\n",
    "                    r.description = r.description+'|{}'.format(organism_temp_dict[organism])\n",
    "                    recs.append(r)\n",
    "                \n",
    "                    inlist_count+=1\n",
    "                except:\n",
    "                    extra_count+=1\n",
    "                    \n",
    "            SeqIO.write(recs, nf, 'fasta')\n",
    "print(\"Count of organisms fastas which are in our org list:\", inlist_count,\"\\nCount of organisms fastas which are not in our org list:\",extra_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAFFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OS = darwin\n",
      "The number of physical cores =  8\n",
      "nthread = 8\n",
      "nthreadpair = 8\n",
      "nthreadtb = 8\n",
      "ppenalty_ex = 0\n",
      "stacksize: 8176 kb\n",
      "rescale = 1\n",
      "Gap Penalty = -1.53, +0.00, +0.00\n",
      "\n",
      "\n",
      "\n",
      "Making a distance matrix ..\n",
      " 7201 / 7225 (thread    5)\n",
      "done.\n",
      "\n",
      "Constructing a UPGMA tree (efffree=0) ... \n",
      " 7220 / 7225\n",
      "done.\n",
      "\n",
      "Progressive alignment 1/2... \n",
      "STEP  6401 / 7224 (thread    5)\n",
      "Reallocating..done. *alloclen = 6033\n",
      "STEP  7001 / 7224 (thread    1)\n",
      "Reallocating..done. *alloclen = 8469\n",
      "\n",
      "Reallocating..done. *alloclen = 9741\n",
      "STEP  7201 / 7224 (thread    6) h\n",
      "Reallocating..done. *alloclen = 10932\n",
      "\n",
      "done.\n",
      "\n",
      "Making a distance matrix from msa.. \n",
      " 7200 / 7225 (thread    0)\n",
      "done.\n",
      "\n",
      "Constructing a UPGMA tree (efffree=1) ... \n",
      " 7220 / 7225\n",
      "done.\n",
      "\n",
      "Progressive alignment 2/2... \n",
      "STEP  6901 / 7224 (thread    0) h\n",
      "Reallocating..done. *alloclen = 6107\n",
      "STEP  7101 / 7224 (thread    5) h\n",
      "Reallocating..done. *alloclen = 7943\n",
      "\n",
      "Reallocating..done. *alloclen = 10256\n",
      "STEP  7201 / 7224 (thread    2) h\n",
      "done.\n",
      "\n",
      "disttbfast (aa) Version 7.520\n",
      "alg=A, model=BLOSUM62, 1.53, -0.00, -0.00, noshift, amax=0.0\n",
      "8 thread(s)\n",
      "\n",
      "\n",
      "Strategy:\n",
      " FFT-NS-2 (Fast but rough)\n",
      " Progressive method (guide trees were built 2 times.)\n",
      "\n",
      "If unsure which option to use, try 'mafft --auto input > output'.\n",
      "For more information, see 'mafft --help', 'mafft --man' and the mafft page.\n",
      "\n",
      "The default gap scoring scheme has been changed in version 7.110 (2013 Oct).\n",
      "It tends to insert more gaps into gap-rich regions than previous versions.\n",
      "To disable this change, add the --leavegappyregion option.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alignment of first 5 sequences:\n",
      "OIQ08369.1|1101268428|biotin\n",
      "OAB45617.1|1025868728|biotin\n",
      "EOD69354.1|486087350|biotin\n",
      "CAG9202857.1|2094294216|biotin\n",
      "PPI56038.1|1345285717|biotin\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "from Bio import AlignIO\n",
    "\n",
    "def run_mafft_large_dataset(input_fasta_file, output_aligned_file):\n",
    "    # Command to run MAFFT with auto parameter selection\n",
    "    # The --thread -1 option tells MAFFT to use all available CPU cores for the alignment, which can significantly speed up the process for large datasets.\n",
    "    mafft_command = [\"mafft\", \"--auto\", \"--thread\", \"-1\", input_fasta_file]\n",
    "    \n",
    "    # Execute MAFFT and capture the output\n",
    "    with open(output_aligned_file, 'w') as outfile:\n",
    "        subprocess.run(mafft_command, stdout=outfile, check=True)\n",
    "    \n",
    "    # Load and print the first few alignments to verify (optional step)\n",
    "    try:\n",
    "        alignment = AlignIO.read(output_aligned_file, \"fasta\")\n",
    "        print(\"Alignment of first 5 sequences:\")\n",
    "        for record in alignment[:5]:  # Print only the first 5 alignments\n",
    "            print(record.id)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading the alignment output: {e}\")\n",
    "\n",
    "input_fasta = \"Lietal_FetchedSeqs/parsed_fastas_cleaned_temped/biotin_carboxylase.fa\"\n",
    "output_aligned = \"Lietal_FetchedSeqs/MAFFT/biotin_carboxylase.fa\"\n",
    "\n",
    "run_mafft_large_dataset(input_fasta, output_aligned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

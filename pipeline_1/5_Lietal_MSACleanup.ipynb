{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. MSA cleanup and collapse by organism, Li et al.\n",
    "___\n",
    "Dr. Raffael lab <br>\n",
    "2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import multiprocessing as mp\n",
    "\n",
    "from Bio.Align import MultipleSeqAlignment\n",
    "from Bio import SeqIO, AlignIO, Seq, SeqRecord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_consensus_seq(msa, enzyme, organism, growth_temp):\n",
    "    \"\"\"\n",
    "    Create consensus sequence for a set of sequences. In this instance,\n",
    "    we calculate a consensus sequence from an MSA of sequences for a \n",
    "    given enzyme and corresponding to a single organism.\n",
    "    \n",
    "    Arguments:\n",
    "        (Bio.Aling.MultipleSeqAlignment) msa:\n",
    "        (str) enzyme: enzyme name\n",
    "        (str) organism: organism corresponding to the supplied MSA\n",
    "        (float) growth_temp: organismal growth temp from Li et al.\n",
    "    \n",
    "    Returns:\n",
    "        (Bio.SeqRecord) organism consensus sequence\n",
    "    \"\"\"\n",
    "    np.random.seed(0)\n",
    "    consensus_list = []\n",
    "    for index in range(msa.get_alignment_length()):\n",
    "        # If the residues are of equal abundance \n",
    "        unique_res, counts = np.unique(list(msa[:,index]), return_counts=True)\n",
    "        if all([count==1 for count in counts]):\n",
    "            rep_res = np.random.choice(unique_res)\n",
    "        else:\n",
    "            rep_res = unique_res[np.argmax(counts)]\n",
    "        if rep_res == '-': #Gap is most common ident\n",
    "            # get the next most common residue\n",
    "            sorted_residue_idents = unique_res[np.argsort(counts)]\n",
    "            if len(sorted_residue_idents) == 1: \n",
    "                # All idents gapped, it's really gapped (will catch in logistic regression)\n",
    "                consensus_list.append('-')\n",
    "            else:\n",
    "                # Get most common non-gap ident in that case\n",
    "                consensus_list.append(sorted_residue_idents[1])\n",
    "        else:\n",
    "            consensus_list.append(rep_res)\n",
    "    consensus_str = ''.join(consensus_list)\n",
    "    consensus_record = SeqRecord.SeqRecord(Seq.Seq(consensus_str), id = '', name = '', \n",
    "                                           description = '{}|{}|{}'.format(enzyme, organism, growth_temp))\n",
    "    return consensus_record\n",
    "\n",
    "\n",
    "def create_consensus_recs(organism_msas_dict, enzyme):\n",
    "    \"\"\"\n",
    "    Create consensus sequence for a set of sequences. In this instance,\n",
    "    we calculate a consensus sequence from an MSA of sequences for a \n",
    "    given enzyme and corresponding to a single organism.\n",
    "    \n",
    "    Arguments:\n",
    "        (dict) organism_msas_dict: dict mapping form organism name\n",
    "            to a Bio.Aling.MultipleSeqAlignment corresponding\n",
    "            to NR DB seqs from that organism. NOTE: these seqs are not \n",
    "            necessarily unique because although they're from NR.gz, many subspecies\n",
    "            share the same sequence but have different accessions.\n",
    "        (str) enzyme: enzyme name\n",
    "    \n",
    "    Returns:\n",
    "        (list) a list of per-organism consensus sequences\n",
    "            (list of Bio.SeqRecord objects)\n",
    "    \"\"\"\n",
    "    return [create_consensus_seq(msa, enzyme, org_temp[0], org_temp[1]) \n",
    "            for org_temp, msa in organism_msas_dict.items()]\n",
    "\n",
    "\n",
    "def create_msas_by_organism(fasta_handle, aln_score_thresh):\n",
    "    \"\"\"\n",
    "    Create consensus MSAs for each organism by collapsing the\n",
    "    per-organism MSA each each position into the most frequent\n",
    "    residues. Gather each consensus sequence into a consensus MSA\n",
    "    AND FILTER THE SEQUENCES BY THE PASSED ALIGNMENT SCORE THRESHOLD.\n",
    "    \n",
    "    Arguments:\n",
    "        (pathlib.Path) fasta_handle:\n",
    "        (float) aln_score_thresh:\n",
    "    \n",
    "    Returns:\n",
    "        (list) a list of Bio.SeqRecord objects (an MSA) containing\n",
    "            per-organism consensus sequences\n",
    "    \"\"\"\n",
    "    retained_records = {}\n",
    "    dumped_recs = []\n",
    "\n",
    "    for rec in SeqIO.parse(fasta_handle, 'fasta'):\n",
    "        desc = rec.description.split('|')\n",
    "        organism = desc[3]\n",
    "        growth_temp = float(desc[4])\n",
    "        aln_score = float(desc[5])\n",
    "        if aln_score > aln_score_thresh:\n",
    "           # if organism in retained_records.keys():\n",
    "            if (organism,growth_temp) in retained_records.keys(): #It should be this instead of above line    \n",
    "                retained_records[(organism, growth_temp)].append(rec)\n",
    "            else:\n",
    "                retained_records[(organism, growth_temp)] = [rec]\n",
    "        else:\n",
    "            dumped_recs.append(rec)\n",
    "    return retained_records\n",
    "\n",
    "\n",
    "def create_export_consensus_aln(fasta_handle, out_root):\n",
    "    \"\"\"\n",
    "    Generates a pseudo alignment of consensus sequences generated\n",
    "    per organism from an MSA (derived from pairwise alignments)\n",
    "\n",
    "    Arguments:\n",
    "        (str) fasta_handle: MSA path\n",
    "        (str) out_root: root folder to which write consensus pseudo alignments\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    with open(fasta_handle, 'r') as msa:\n",
    "        reference_header = msa.readline().strip()[1:]\n",
    "        reference_seq = msa.readline().strip()[1:]\n",
    "    \n",
    "    aln_threshold = float(reference_header.split('|')[-1])\n",
    "    fasta_path = Path(fasta_handle)\n",
    "    enzyme_name = fasta_path.stem\n",
    "    \n",
    "    retained_records = create_msas_by_organism(fasta_path, aln_threshold)\n",
    "    organism_msas = {organism:MultipleSeqAlignment(recs) for organism, recs in retained_records.items()}\n",
    "    consensus_recs = create_consensus_recs(organism_msas, enzyme_name)\n",
    "    \n",
    "    out_path = Path(out_root).joinpath('{}.consensus.aln'.format(enzyme_name))\n",
    "    with open(out_path, 'a+') as consensus_output:\n",
    "        consensus_output.write(';{}\\n;{}\\n'.format(reference_header, reference_seq))\n",
    "        SeqIO.write(consensus_recs, consensus_output,'fasta')\n",
    "\n",
    "\n",
    "def create_export_consensus_aln_chunked(fasta_handle_list, out_root):\n",
    "    \"\"\"\n",
    "    Wrapper to generate consensus alignments in groups. Needed\n",
    "    for following progress while parallelizing\n",
    "    \n",
    "    Arguments:\n",
    "        (list) fasta_handle_list: list of paths corresponding to per-enzyme\n",
    "            MSAs\n",
    "        (str) out_root: folder in which to export consensus alignments\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \n",
    "    \"\"\"\n",
    "    for handle in fasta_handle_list:\n",
    "        create_export_consensus_aln(handle, out_root)\n",
    "        \n",
    "\n",
    "def msa_to_csv(msa_handle, out_root):\n",
    "    \"\"\"\n",
    "    Parses a multiple sequence alignment of consensus sequences into a long-form\n",
    "    CSV with each entry (row) a single position and organism, with growth temperature.\n",
    "    \n",
    "    Arguments:\n",
    "        (str | pathlib.Path) msa_handle: path of consensus MSA fasta to convert\n",
    "            to long CSV form\n",
    "        (str) out_root: folder in which to export consensus alignments\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \n",
    "    \"\"\"\n",
    "    consensus_msa = AlignIO.read(msa_handle, 'fasta')\n",
    "\n",
    "    header_ids = ('Enzyme_Name', 'Organism', 'Temperature')\n",
    "\n",
    "    msa_range = range(1, consensus_msa.get_alignment_length()+1)\n",
    "    rec_df = pd.DataFrame([{\n",
    "            **dict(zip(header_ids, rec.description.strip().split('|'))), \n",
    "            **dict(zip(msa_range, list(rec.seq)))} \n",
    "            for rec in consensus_msa]).melt(id_vars = header_ids, value_name = 'Consensus_Residue',\n",
    "                                            value_vars = msa_range, var_name = 'Position')\n",
    "\n",
    "#     out_path = out_root.joinpath(msa_handle.stem + '_summary.csv.bz2')#for multiple enzymes use this\n",
    "    out_path = out_root.joinpath(msa_handle.stem + '_summary.csv') # for single enzyme use this\n",
    "    rec_df.to_csv(out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Parallelized consensus generation (~75 min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_root = Path('Lietal_PairwiseAlns/')\n",
    "out_root = 'Lietal_ConsensusAlns/'\n",
    "\n",
    "msas = np.array([str(p) for p in msa_root.iterdir() if not '.ipynb_checkpoints' in str(p)])\n",
    "msa_sizes = [p.stat().st_size for p in msa_root.iterdir() if not '.ipynb_checkpoints' in str(p)]\n",
    "sorted_msas = msas[np.argsort(msa_sizes)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating consensus alignments: 100%|██████████| 80/80 [1:15:51<00:00, 56.90s/it] \n"
     ]
    }
   ],
   "source": [
    "# numchunks = 80\n",
    "# for msa_handle_list in tqdm(np.array_split(sorted_msas, numchunks), total = numchunks, \n",
    "#                             desc = 'Generating consensus alignments'):\n",
    "\n",
    "#     numthreads = 24\n",
    "#     pool = mp.Pool(numthreads)\n",
    "#     results = []\n",
    "\n",
    "#     result_objects = [pool.apply_async(create_export_consensus_aln_chunked, args=(fasta_handle_list, out_root)) \n",
    "#                       for fasta_handle_list in np.array_split(msa_handle_list, numthreads)\n",
    "#                      ]\n",
    "\n",
    "#     pool.close()\n",
    "#     pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For multiple enzymes use above code\n",
    "\n",
    "\n",
    "result_objects = [create_export_consensus_aln_chunked(sorted_msas, out_root)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate \"long\" per enzyme CSV representations, for logistic regression (~15min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 2194 MSAs in 92 Chunks\n"
     ]
    }
   ],
   "source": [
    "# msa_root = Path('Lietal_ConsensusAlns/')\n",
    "\n",
    "# out_root = Path('Lietal_PerPositionSummaries')\n",
    "\n",
    "\n",
    "# MAX_THREADS = 24\n",
    "\n",
    "# # Obtain msa handles and sort by size to make parallelization more performant\n",
    "# all_msas = np.array([Path(msa_handle) for msa_handle in msa_root.iterdir() if not str(msa_handle.stem).startswith('.')])\n",
    "# all_msas_sorted = all_msas[np.argsort([Path(msa).stat().st_size for msa in all_msas])]\n",
    "\n",
    "# msa_chunks = np.array_split(all_msas_sorted, (len(all_msas_sorted)//MAX_THREADS)+1)\n",
    "# print('Processing {} MSAs in {} Chunks'.format(sum([len(c) for c in msa_chunks]), len(msa_chunks)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PosixPath('Lietal_ConsensusAlns/steroid_DELTA-isomerase.consensus.aln')] [PosixPath('Lietal_ConsensusAlns/steroid_DELTA-isomerase.consensus.aln')]\n"
     ]
    }
   ],
   "source": [
    "#For multiple enzymes run above cell for setup\n",
    "\n",
    "msa_root = Path('Lietal_ConsensusAlns/')\n",
    "\n",
    "out_root = Path('Lietal_PerPositionSummaries')\n",
    "\n",
    "\n",
    "\n",
    "# Obtain msa handles and sort by size to make parallelization more performant\n",
    "all_msas = np.array([Path(msa_handle) for msa_handle in msa_root.iterdir() if not str(msa_handle.stem).startswith('.')])\n",
    "all_msas_sorted = all_msas[np.argsort([Path(msa).stat().st_size for msa in all_msas])]\n",
    "\n",
    "# msa_chunks = np.array_split(all_msas_sorted, (len(all_msas_sorted)//MAX_THREADS)+1)\n",
    "# print('Processing {} MSAs in {} Chunks'.format(sum([len(c) for c in msa_chunks]), len(msa_chunks)))\n",
    "print(all_msas,all_msas_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating CSV representations: 100%|██████████| 92/92 [15:36<00:00, 10.18s/it]\n"
     ]
    }
   ],
   "source": [
    "# for msa_handle_list in tqdm(msa_chunks, total = len(msa_chunks), \n",
    "#                             desc = 'Generating CSV representations'):\n",
    "\n",
    "#     numthreads = len(msa_handle_list)\n",
    "#     pool = mp.Pool(numthreads)\n",
    "\n",
    "#     result_objects = [pool.apply_async(msa_to_csv, args=(msa_handle, out_root)) \n",
    "#                       for msa_handle in msa_handle_list]\n",
    "\n",
    "#     pool.close()\n",
    "#     pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For multiple enzymes run above cell\n",
    "\n",
    "result_objects = [msa_to_csv(i, out_root) for i in all_msas_sorted]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
